\part{Algorithm strategies}
\frame{\partpage}

\newcommand{\weight}{\operatorname{weight}}
\newcommand{\val}{\operatorname{value}}
\newcommand{\best}{{\text{best}}}

\begin{frame}{The knapsack problem}
	\begin{itemize}
		\pause\item There is a set $X$ of \textbf{items}
		\pause\item Each item $x$ has a weight $\weight(x)$ and a value $\val(x)$
		\pause\item There is a maximum weight $W$
		\pause\item What subset $S \subseteq X$ maximises the total value, whilst not exceeding the maximum weight?
		\pause\item In other words: find $S \subseteq X$ to maximise
			$$ \sum_{x \in S} \val(x) $$
		subject to
			$$ \sum_{x \in S} \weight(x) \leq W $$
	\end{itemize}
\end{frame}

\begin{frame}{Algorithm strategies}
	\begin{itemize}
		\pause\item Brute force
		\pause\item Greedy
		\pause\item Divide-and-conquer
		\pause\item Dynamic programming
	\end{itemize}
\end{frame}

\begin{frame}{Brute force}
	\begin{itemize}
		\pause\item Try \textbf{every possible} solution and decide which is best
	\end{itemize}
	\pause
	\begin{algorithmic}
		\Procedure{Knapsack}{X, W}
			\pause\State $S_\best \gets \{ \}$
			\pause\State $v_\best \gets 0$
			\pause\For{every subset $S \subseteq X$}
				\pause\If{$\weight(S) \leq W$ and $\val(S) > v_\best$}
					\pause\State $S_\best \gets S$
					\pause\State $v_\best \gets \val(S)$
				\pause\EndIf
			\pause\EndFor
			\pause\State \textbf{return} $S_\best$
		\pause\EndProcedure
	\end{algorithmic}
\end{frame}

\begin{frame}{Socrative \texttt{FALCOMPED}}
	\begin{itemize}
		\pause\item If $X$ contains $n$ elements, how many subsets of $X$ are there?
		\pause\item Therefore what is the time complexity of the brute force algorithm?
		\pause\item If we add one element to $X$, what happens to the running time of the algorithm?
	\end{itemize}
\end{frame}

\begin{frame}{Greedy algorithm}
	\begin{itemize}
		\pause\item At each stage of building a solution, take the \textbf{best} available option
	\end{itemize}
	\pause
	\begin{algorithmic}
		\Procedure{Knapsack}{X, W}
			\pause\State $S \gets \{ \}$
			\pause\For{each $x \in X$, in descending order of $\val(x)$}
				\pause\If{$\weight(S) + \weight(x) \leq W$}
					\pause\State add $x$ to $S$
				\pause\EndIf
			\pause\EndFor
			\pause\State \textbf{return} $S$
		\EndProcedure
	\end{algorithmic}
\end{frame}

\begin{frame}{Greedy algorithm}
	\begin{itemize}
		\pause\item Time complexity is dominated by sorting $X$ by value
		\pause\item The rest of the algorithm runs in linear time
		\pause\item In some problems an appropriately chosen greedy solution is \textbf{optimal}
			\begin{itemize}
				\pause\item A$^*$ pathfinding
				\pause\item Huffman coding
			\end{itemize}
		\pause\item \textbf{However} the greedy solution to the knapsack problem may not be optimal!
	\end{itemize}
\end{frame}

\begin{frame}{Divide and conquer}
	\begin{itemize}
		\pause\item Break the problem into smaller, easier to solve \textbf{subproblems}
		\pause\item Requires that the solution to the original problem is composed of the solutions to the smaller problem
		\pause\item Example from last time: \textbf{binary search}
			\begin{itemize}
				\pause\item Problem: find an element in a list
				\pause\item Subproblem: find the element in a list of half the size
			\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Divide and conquer for the knapsack problem}
	\begin{itemize}
		\pause\item Consider an element $x \in X$ with $\weight(x) \leq W$
		\pause\item Let $X'$ be $X$ with $x$ removed
		\pause\item The solution to the knapsack problem either includes $x$ or it doesn't
		\pause\item The solution is \textbf{either}:
			\begin{itemize}
				\pause\item The solution to the knapsack problem on $X'$ with maximum weight $W$, \textbf{or}
				\pause\item The solution to the knapsack problem on $X'$ with maximum weight $W - \weight(x)$,
					plus $x$
			\end{itemize}
		\pause\item ... whichever has the greater value
		\pause\item Base case: the solution to the knapsack problem on the empty set \textbf{is} the empty set
	\end{itemize}
\end{frame}

\begin{frame}{Divide and conquer for the knapsack problem}
	\begin{algorithmic}
		\pause\Procedure{Knapsack}{X, W, k}
			\pause\If{$k < 0$}
				\pause\State \textbf{return} $\{\}$
			\pause\EndIf
			
			\pause\State $S \gets \Call{Knapsack}{X, W, k-1}$
			\pause\If{$\weight(x_k) \leq W$}
				\pause\State $S' \gets \Call{Knapsack}{X, W - \weight(x_k), k-1} \cup \{x_k\}$
				\pause\State \textbf{return} whichever of $S,S'$ has the larger value
			\pause\Else
				\pause\State \textbf{return} $S$
			\pause\EndIf
		\pause\EndProcedure
	\end{algorithmic}
\end{frame}

\begin{frame}{Time complexity}
	\begin{itemize}
		\pause\item Each call to \Call{Knapsack}{} has, in the worst case, \textbf{two} recursive calls to \Call{Knapsack}{}
		\pause\item Number of calls is
			$$ \underbrace{1 + 2 + 4 + 8 + \dots + 2^i + \dots}_{\text{$n$ terms}} $$
		\pause\item Thus the worst case time complexity is $O(2^n)$ --- still exponential!
		\pause\item However in the \textbf{average} case many of the calls have only a single recursive call,
			so this is still more efficient than brute force
	\end{itemize}
\end{frame}

\begin{frame}{Overlapping subproblems}
	\begin{itemize}
		\pause\item Here we end up solving the \textbf{same subproblem multiple times}
		\pause\item Can save time by \textbf{caching} (remembering) these sub-solutions
		\pause\item This is called \textbf{memoization}
		\pause\item One of several techniques in the category of \textbf{dynamic programming}
	\end{itemize}
\end{frame}

\begin{frame}{Dynamic programming for the knapsack problem}
    {\small
	\begin{algorithmic}
		\pause\Procedure{Knapsack}{X, W, k}
			\pause\If{\Call{Knapsack}{X, W, k} has already been computed}
				\pause\State \textbf{return} previously computed result
			\pause\EndIf
			
			\pause\If{$k < 0$}
				\State \textbf{cache and return} $\{\}$
			\EndIf
			
			\State $S \gets \Call{Knapsack}{X, W, k-1}$
			\If{$\weight(x_k) \leq W$}
				\State $S' \gets \Call{Knapsack}{X, W - \weight(x_k), k-1} \cup \{x_k\}$
				\State \textbf{cache and return} whichever of $S,S'$ has the larger value
			\Else
				\State \textbf{cache and return} $S$
			\EndIf
		\EndProcedure
	\end{algorithmic}
	}
\end{frame}

\begin{frame}{Socrative \texttt{FALCOMPED}}
	\begin{itemize}
		\pause\item What is the maximum possible number of entries in the table of intermediate results?
		\pause\item Therefore what is the time complexity of the dynamic programming algorithm?
	\end{itemize}
\end{frame}

\begin{frame}{Summary of algorithm strategies}
	\begin{itemize}
		\pause\item Brute force
			\begin{itemize}
				\pause\item Good enough for small/simple problems
			\end{itemize}
		\pause\item Greedy
			\begin{itemize}
				\pause\item Efficient for certain problems, but doesn't always give optimal solutions
			\end{itemize}
		\pause\item Divide-and-conquer
			\begin{itemize}
				\pause\item Good if the problem can be broken down into simpler subproblems
			\end{itemize}
		\pause\item Dynamic programming
			\begin{itemize}
				\pause\item Makes divide-and-conquer more efficient if subproblems often reoccur
			\end{itemize}
	\end{itemize}
\end{frame}

