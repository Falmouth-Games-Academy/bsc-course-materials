\part{Post-processing}
\frame{\partpage}

\begin{frame}{What is Post-Processing?}
	\begin{itemize}
		\pause\item A series of techniques that are carried out \textbf{after} a scene has been rendered
		\pause\item Typically mimic effects caused by camera (or eye) hardware, e.g. lens flare, bloom, motion blur
		\pause\item Traditionally this could only be done as an offline process
		\pause\item With the advent of faster GPUs and programmable shaders, we can implement some of the effects in real time
	\end{itemize}
\end{frame}

\begin{frame}{Post-Processing Stages}
	\begin{itemize}
		\pause\item The key to the effect is to switch from drawing to the back buffer to a \textbf{texture}
		\pause\item This texture will contain the current view of the scene
		\pause\item We then use a shader to implement a post-processing effect
		\pause\item We then map the processed texture onto a full screen quad, which is rendered to the backbuffer
	\end{itemize}
\end{frame}

\begin{frame}{The Frame Buffer}
	\begin{itemize}
		\pause\item We use several types of \textbf{screen buffers} when rendering with OpenGL:
		\begin{itemize}
			\pause\item The \textbf{colour buffer} stores the pixel output from the fragment shaders.
			\pause\item The \textbf{depth buffer} (or $z$-buffer) stores information for depth-testing.
			\pause\item A \textbf{stencil buffer} can be used to mask out certain fragments.
		\end{itemize}
		\pause\item A \textbf{framebuffer} is just a combination of different buffers.
		\pause\item A default framebuffer is created for you; you can create additional ones to render to instead.
	\end{itemize}
\end{frame}